{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Short Description\n",
    "\n",
    "K-Means clustering is a simple partitional clustering algorithm.\n",
    "\n",
    "Partitional means that it separates the space into 'K' spaces with no overlapping spaces. This is in contrast with Hierarchical Clustering, which can have 'subspaces' within other spaces. \n",
    "\n",
    "K-Means works by setting 'centroids' in these spaces, and assigning data points to spaces with the closest centroid. \n",
    "\n",
    "For every cluster, in every dimension, we measure the 'euclidean distance' (straight line) between the centroid and the data point inside that cluster.\n",
    "\n",
    "$$\\sum _{{\\text{Cluster }}C_{i}}\\,\\sum _{{\\text{Dimension }}d}\\,\\sum _{x,y\\,\\in \\,C_{i}}(x_{d}-y_{d})^{2}$$\n",
    "\n",
    "The number of clusters is tunable, and we call the number of clusters 'K', the process is repeated until the clusters converge on the optimal number of clusters with the minimal centroids. \n",
    "\n",
    "Minimizing error over all clusters with respect to the 2-norm distance metric\n",
    "\n",
    "# When to use this, over others\n",
    "\n",
    "K-Means should be the first stop for clustering problems. There are much more sophisticated algorithms that perform better but are nearly always much more computationally expensive and complex to explain\n",
    "\n",
    "K-Means is not a free pass to good clustering, but it is extremely easy to use and most of the time performs pretty well, there are cases where K-Means can fool you However,\n",
    "\n",
    "Run k-means on uniform data, and you will still get clusters! It doesn't tell you when the data just does not cluster, and can take your research into a dead end this way.\n",
    "\n",
    "K-means assumes the variance of the distribution of each attribute (variable) is spherical; (clustering on uniform data will fail)\n",
    "\n",
    "all variables have the same variance;\n",
    "\n",
    "the prior probability for all k clusters is the same, i.e., each cluster has roughly equal number of observations;\n",
    "\n",
    "https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means\n",
    "\n",
    "# Algorithm Assumptions\n",
    "\n",
    "We are using clusterable data\n",
    "That data is spherical data\n",
    "clusters are relatively evenly sized\n",
    "\n",
    "# Performance Metrics\n",
    "\n",
    "Percentage of Variance Explained (PVE) \n",
    "\n",
    "The Elbow Method to decide the number of clusters in k-means algorithm. \n",
    "\n",
    "K-means is a clustering algorithm that tries to partition a set of points into K sets (clusters) such that the points in each cluster tend to be near each other. It is unsupervised because the points have no external classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
