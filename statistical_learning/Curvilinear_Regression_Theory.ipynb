{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvilinear Regression\n",
    "\n",
    "Linear regression aims to find the relationship between a dependent variably Y and independent variable X where flexibility is required. This can be any somewhat consecutive string of dots, that are not linear.\n",
    "\n",
    "X is sometimes referred to as an explanatory variablee.\n",
    "\n",
    "When used to predict, X is called a feature.. and the prediction is called a response (Y)\n",
    "\n",
    "curvilinear regression uses exponents of the independent variable X to predict a single dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>The Linear Regression Equation</center>\n",
    "Linear Regression\n",
    "### $$\\hat{y} = \\beta_1x + \\beta_0$$\n",
    "Curvilinear Regression\n",
    "### $$\\hat{y} = \\beta_1x^1 +  \\beta_2x^2 +  \\beta_3x^3 +  \\beta_4x^4 + \\beta_0$$\n",
    "This equation causes a curve in the line for each exponent. The above equation would be a similar to the below graph.\n",
    "<img style=\"width:10rem;height:10rem\" src=\"img/polynomial.png\">\n",
    "What does each term represent?\n",
    "- $y$ is the response or set of responses\n",
    "- $x^n$ is the feature or exponential version of the feature\n",
    "- $\\beta_0$ is the intercept, or bias\n",
    "- $\\beta_n$ is the coefficient for $x^n$, or the 'prediction coefficient'\n",
    "\n",
    "$$B_n = \\frac{\\sum((x_i-\\bar{x})\\times(y_i-\\bar{y}))}{\\sum(x_i–\\bar{x}^2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "These statistics are meant to help you evaluate the strength of the relationship between input and output. Now that you have the slope and intercept, you have a 'model'\n",
    "\n",
    "The statistics are explained below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The null hypothesis and the P-Value\n",
    "\n",
    "what if your prediction is completely wrong? And there is no relation\n",
    "\n",
    "thats what P-Value tries to tell you, P ranges from 0 to 1\n",
    "\n",
    "A high p-value tries to tell you that you are compatible with the null hypothesis, meaning your prediction is probably wrong\n",
    "\n",
    "A low p-value shows that your prediction is not in line with the null hypothesis, meaning your prediction may be correct\n",
    "\n",
    "Example a P-Value of .05, means that if you reject the null hypothesis.. there is a 5% chance you are wrong.\n",
    "\n",
    "Its good practice to multiple your P-Value rate by ~5x. so .05 would be better thought of as 25% wrong\n",
    "\n",
    "As a note, repeatability is always the most important thing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R: Correlation Coefficient\n",
    "\n",
    "The r value is the measure of how closely the two inputs are related.\n",
    "\n",
    "r ranges from -1 to +1 and the closer it is to either side, the closer the variables are related\n",
    "\n",
    "the variables are either posivitely correlated: increasing together (+1), inversley correlated: increasing oppositely (-1) or not corelated: unpredictable (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $R^2$: How well does my model explain the variance\n",
    "\n",
    "\n",
    "Squaring R gives you a % of how well the model explains the variance\n",
    "an R^2 of 1 means that all the variance was explained by the model\n",
    "R^2 of 0 means none of the variance was explained by the model\n",
    "\n",
    "R-squared cannot determine whether the coefficient estimates and predictions are biased, which is why you must assess the residual plots.\n",
    "\n",
    "R-squared does not indicate whether a regression model is adequate. You can have a low R-squared value for a good model, or a high R-squared value for a model that does not fit the data!\n",
    "\n",
    "R^2 is generally not the best stat to use for making assumptions about your model\n",
    "https://stats.stackexchange.com/questions/13314/is-r2-useful-or-dangerous\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# Regression metrics\n",
    "\n",
    "#The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better.\n",
    "\n",
    "mse = metrics.mean_squared_error(Y, prediction)\t#Mean squared error regression loss\n",
    "\n",
    "\n",
    "#Mean Absolute Error (MAE) is the average vertical distance between each point and the Y=X line, which is also known as the One-to-One line.\n",
    "\n",
    "mar = metrics.mean_absolute_error(Y, prediction)\t#Mean absolute error regression loss\n",
    "\n",
    "\n",
    "#same as R2 but takes into account the mean of the error, best value is 1.. less is worse\n",
    "\n",
    "exp_v = metrics.explained_variance_score(Y, prediction)\t#Explained variance regression score function\n",
    "\n",
    "\n",
    "\n",
    "#median absolute error, robust to outliers \n",
    "\n",
    "mae = metrics.median_absolute_error(Y, prediction)\t\n",
    "\n",
    "#between -1 and 1, 0 is best\n",
    "\n",
    "r2 = metrics.r2_score(Y, prediction)\t#R^2 (coefficient of determination) regression score function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope and Intercept\n",
    "\n",
    "the slope and intercept are used to create the function that allows you to make predictions about new data\n",
    "\n",
    "using the 'model' equation you can plug in a new X to find the predicted Y for that X\n",
    "\n",
    "if your statistics show a strong relationship between input and output, then your prediction has a good chance of being meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering the residual\n",
    "### $$y = \\beta_1x + \\beta_0 + \\epsilon$$\n",
    "\n",
    "The residual $\\epsilon$ is calculated as the difference between the dependant variable $y$, and the prediction $\\hat{y}$\n",
    "\n",
    "$$\\epsilon = y - \\hat{y}$$\n",
    "\n",
    "A good way to use this data is to plot it on a graph against the independent variable $x$ and try to detect a pattern.\n",
    "\n",
    "If no pattern exists, your modeel probably does a fairly good job explaining the data or at the very least, there is no obviously missing feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
