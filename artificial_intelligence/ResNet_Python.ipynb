{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-Activation Wide-ResNet Network for Spectrum Mining and Modulation Detection.\n",
    "\n",
    "References:\n",
    "    Basic ResNet: https://arxiv.org/pdf/1512.03385.pdf\n",
    "    Pre-Act. ResNet: https://arxiv.org/pdf/1603.05027.pdf\n",
    "    Wide-ResNet: https://arxiv.org/pdf/1605.07146v1.pdf\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "\n",
    "# tuple for model hyperparameters\n",
    "HyperParams = namedtuple('HyperParams',\n",
    "                     'batch_size, num_chans_in, height, width, filter_dims,'\n",
    "                     'lr, kernel_dims, strides, n_hidden, relu_alpha')\n",
    "# sample hyperparameters\n",
    "h = HyperParams(128, 1, 20, 512, [16, 16, 16, 32, 64], 1e-5, [3, 3],\n",
    "                [1, 1, 1, 2, 2], 128, 0.01)\n",
    "\n",
    "# parameters for batch_norm\n",
    "_BATCH_NORM_DECAY = 0.997\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "\n",
    "def ResNet(object):\n",
    "    def __init__(self, hps=h):\n",
    "\n",
    "        # parameters and inputs\n",
    "        self.batch_size = 128 # hps.batch_size\n",
    "        num_chans = 1 # hps.num_chans_in\n",
    "        height = 20 # hps.height\n",
    "        width = 512 # hps.width\n",
    "\n",
    "        # placeholder for inputs and training flag\n",
    "        self.inputs = tf.placeholder(tf.float32,\n",
    "            shape=(None, num_chans, height, width), name='x_placeholder')\n",
    "        self.is_training = tf.placeholder_with_default(True, [],\n",
    "            name='is_training')\n",
    "\n",
    "        # network parameters\n",
    "        self.n_filts = [16, 16, 16, 32, 64] # hps.filter_dims\n",
    "        # self.n_filts = [16, 16, 80, 160, 320] # params for wide-resnet(5,4)\n",
    "        self.kernel_dim = (3, 3) # hps.kernel_dims\n",
    "        self.strides = [1, 1, 1, 2, 2] # hps.strides\n",
    "        self.n_hidden = 128 # hps.n_hidden\n",
    "        self.relu_alpha = hps.relu_alpha\n",
    "        # initializers\n",
    "        self.conv_init = tf.contrib.layers.xavier_initializer_conv2d\n",
    "        self.dense_init = tf.contrib.layers.xavier_initializer\n",
    "\n",
    "        # forward pass through resnet\n",
    "        self.inference = self._get_inference()\n",
    "        # get loss from output\n",
    "        self.loss = self._get_loss()\n",
    "        # get optimizer step to minimize loss\n",
    "        self.optim = self._get_optimizer()\n",
    "\n",
    "    def _get_inference(self):\n",
    "        x = self._get_first_layer()\n",
    "        x = self._build_model(x)\n",
    "        return x\n",
    "\n",
    "    def _get_first_layer(self):\n",
    "        '''\n",
    "        Return the first convolutional layer common to all ResNet models.\n",
    "\n",
    "        Note: Slightly different from layer + pooling in original resnet, but\n",
    "            this performs better.\n",
    "        '''\n",
    "        with tf.variable_scope('first_layer'):\n",
    "            x = tf.layers.conv2d(self.inputs, filters=self.n_filts[0],\n",
    "                kernel_size=self.kernel_dim, strides=self.strides[0],\n",
    "                kernel_initializer=tf.conv_init, padding='same')\n",
    "            return x\n",
    "\n",
    "    def _build_model(self, x):\n",
    "        '''Builds the residual blocks.'''\n",
    "        # scales better for deeper resnet blocks\n",
    "        # for i in range(1, len(self.n_filts)):\n",
    "        #     with tf.variable_scope('resnet_block_{:d}'.format(i)):\n",
    "        #         x = self._resnet_block(x, self.n_filts[i], self.strides[i],\n",
    "        #             self.training_pl)\n",
    "\n",
    "        with tf.variable_scope('first_block'):\n",
    "            x = self._resnet_block(x, self.n_filts[1], self.strides[1],\n",
    "                self.training_pl)\n",
    "\n",
    "        with tf.variable_scope('second_block'):\n",
    "            x = self._resnet_block(x, self.n_filts[2], self.strides[2],\n",
    "                self.training_pl)\n",
    "\n",
    "        with tf.variable_scope('third_block'):\n",
    "            x = self._resnet_block(x, self.n_filts[3], self.strides[3],\n",
    "                self.training_pl)\n",
    "\n",
    "        with tf.variable_scope('fourth_block'):\n",
    "            x = self._resnet_block(x, self.n_filts[4], self.strides[4],\n",
    "                self.training_pl)\n",
    "\n",
    "        with tf.variable_scope('GAP_block'):\n",
    "            # NOTE: assumes channels_first\n",
    "            x = tf.reduce_mean(x, [2, 3])\n",
    "\n",
    "        with tf.variable_scope('dense_out'):\n",
    "            x = tf.reshape(x, [self.batch_size, -1])\n",
    "            x = tf.layers.dense(x, self.n_hidden, activation=self._leaky_relu,\n",
    "                    kernel_initializer=self.dense_init)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _resnet_block(self, inputs, in_filts, strides, is_training):\n",
    "        '''\n",
    "        ResNet block with two convolutions.\n",
    "        Projects original inputs through 1x1 conv if strides downsample.\n",
    "        '''\n",
    "        # store original x for skip-connection\n",
    "        orig_in = inputs\n",
    "\n",
    "        # if we are down-sampling, need to double amount of filters\n",
    "        if strides == 2:\n",
    "            in_filts *= 2\n",
    "\n",
    "        # first pre-activation block\n",
    "        inputs = self._batch_norm_relu(inputs, is_training)\n",
    "        inputs = tf.layers.conv2d(inputs, in_filts, self.kernel_dim, strides,\n",
    "            padding='same', data_format='channels_first',\n",
    "            kernel_initializer=self.conv_init)\n",
    "\n",
    "        # second pre-activation block\n",
    "        inputs = self._batch_norm_relu(inputs, is_training)\n",
    "        inputs = tf.layers.conv2d(inputs, in_filts, self.kernel_dim, strides,\n",
    "            padding='same', data_format='channels_first',\n",
    "            kernel_initializer=self.conv_init)\n",
    "\n",
    "        # add back original inputs, with projection if needed\n",
    "        if strides == 2:\n",
    "            # 1x1 conv with downsample strides and filters\n",
    "            orig_in = tf.conv2d(orig_in, in_filts, (1, 1), strides,\n",
    "                padding='same', data_format='channels_first',\n",
    "                kernel_initializer=self.conv_init)\n",
    "        inputs += orig_in\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def _batch_norm_relu(self, inputs, is_training):\n",
    "        '''\n",
    "        Passes inputs through batch normalization and leaky-relu.\n",
    "        '''\n",
    "        inputs = tf.layers.batch_normalization(inputs, axis=3, momentum=_BATCH_NORM_DECAY,\n",
    "            epsilon=_BATCH_NORM_EPSILON, center=True, scale=True, training=is_training,\n",
    "            fused=True)\n",
    "        inputs = self._leaky_relu(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def _leaky_relu(self, inputs, alpha=0.01):\n",
    "        return tf.maximum(self.relu_alpha * inputs, inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
