{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have a set of data, but no matching set of labels. This can happen for a variety of reasons:\n",
    "    1. Labeling data is expensive and time consuming.\n",
    "    2. Finding labeled data that captures a wide variety of real-world situations and use-cases is difficult.\n",
    "    3. Labeled data must often be manually curated to ensure good annotation quality, else it defeats the point of labels.\n",
    "The list above shows that getting large quantities of unlabeled data is usually faster and infinitely more economical than gathering a matching, labeled dataset. \n",
    "\n",
    "However, so much of the current Deep Learning wave was built on large, labeled datasets (i.e. ImageNet and SRE competitions) that it begs the question: do large yet unlabeled datasets still have a role? This is the realm of Unsupervised Learning, where there is no mapping from X -> Y to learn because Y either does not exist or we do not have it. It is the least common form of learning compared to Classification and Regression and is likewise the most loosely defined. In Unsupervised Learning the goal is typically to discover some hidden characteristics, qualities, or structure in the data.\n",
    "\n",
    "One of the first methods that made it possible to train large nets was based on Unsupervised Learning. Before many of the more advanced initialization schemes (i.e. Glorot and He), Deep Nets were initialized with something called `Unsupervised Pre-Training`. The `Restricted Boltzman Machine` (RBM) was as at the heart of this initialization scheme. It is, to oversimplify, a two-layer neural network. The first input layer is called the \"visible\" layer while the second layer is called the \"hidden\" layer. The main idea is to learn a hidden layer distribution that is a good representation of the input. This is analogous to the idea of finding those hidden qualities or structures in the unlabeled training data. Deep Networks were initialized in a greedy, layer-by-layer fashion using RBMs to reconstruct the input at each successive layer. This led to `Deep Belief Nets`, a sort of precursor to the Deep Feedforward Network more common today. \n",
    "\n",
    "The idea of reconstructing the original input based on the activation of the \"hidden\" layer leads very naturally to the idea of an `Autoencoder`. Where an RBM is usually only two layers deep, and Autoencoder will look more like a typical DNN with multiple layers. Autoencoders usually have a single layer that is much smaller than the others. This is known as the `bottleneck` layer whose goal is forcing the DNN to compress its internal representation into a compact version that captures the most important and distingushing characteristics of the input. Autoencoders are usually trained end-to-end like standard DNNs instead of layer-by-layer. \n",
    "\n",
    "If an Autoencoder learns to reconstruct its input, then the hope is that its intermediate layers (especially the bottleneck layer) learned to identify the most important characteristics of the input. This is similar to the idea of compressions for storing audio and video files. The bottleneck activations can then be used as features for another network or model in a variety of ways. Likewise, if we want to find good features for reconstructing the input, the most natural cost is how well our Autoencoder ouput matches the original inputs. This is called the reconstruction error and is defined as `(original - reconstruction)^2`. To optimize our network we then minimize this reconstruction error for all samples in a minibatch across epochs.  \n",
    "\n",
    "A popular Autoencoder architecuture is that of the Encoder-Decoder. Here, an Encoder compresses the input down the bottleneck layer. This could be achieved with a series of dense, convolutional, or recurrent layers. The Decoder is usually a mirrored version of the Encoder that restores the bottleneck back to original input dimensions, although it can also be a completely separate network (i.e. for image captioning and language translation tasks). We will see a simple Encoder-Decoder in the `Python` section of this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising Autoencoders\n",
    "\n",
    "While the ideas of Autoencoders and Encoder-Decoders are very powerful on the surface, there are many pitfalls to consider. Imagine if the dataset only captures a small subset of the conditions and samples that our network will see in the real world. Our learned bottleneck features will have never seen this new data and will thus handle it poorly. On the other hand, if we build a large network then it could vastly overfit the training set and perform poorly on new data even if it comes from the same source and distribution. \n",
    "\n",
    "One of the first ideas for tackling this problem was building `Denoising Autoencoders`. Here we distort and corrupt the original input before feeding it into the network. However, when we calculate the cost we still compare the reconstruction to the original, uncorrupted inputs. This ideally forces the network to learn more robust features that can handle noise in the inputs. The network will then better handle unseen cases since it did not rigidly fit the clean training set. Furthermore, it was shown that applying Gaussian noise at the inputs is similar to L2 (i.e. Energy norm, or weight-decay) regularization [ref]. This again prevents the network from overfitting its training set.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoders\n",
    "\n",
    "Recently, a new flavor of Autoencoders [Kingma ref] is performing very well across a variety of tasks. They are also related to the well-established field of Bayesian Inference and carry the host of theory of methods from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Convolutional Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
